model_name,organization,release_date,source_url,report_path,notes,AI2D (test),AI2D (test)__setting,AMC 10,AMC 10__setting,AMC 12,AMC 12__setting,AP Art History,AP Art History__setting,AP Biology,AP Biology__setting,AP Calculus BC,AP Calculus BC__setting,AP Chemistry,AP Chemistry__setting,AP English Language and Composition,AP English Language and Composition__setting,AP English Literature and Composition,AP English Literature and Composition__setting,AP Environmental Science,AP Environmental Science__setting,AP Macroeconomics,AP Macroeconomics__setting,AP Microeconomics,AP Microeconomics__setting,AP Physics 2,AP Physics 2__setting,AP Psychology,AP Psychology__setting,AP Statistics,AP Statistics__setting,AP US Government,AP US Government__setting,AP US History,AP US History__setting,AP World History,AP World History__setting,ARC-Challenge,ARC-Challenge__setting,Advanced Sommelier (theory knowledge),Advanced Sommelier (theory knowledge)__setting,BIG-Bench Hard,BIG-Bench Hard__setting,Bar Exam (MBE multiple-choice),Bar Exam (MBE multiple-choice)__setting,CSQA,CSQA__setting,Certified Sommelier (theory knowledge),Certified Sommelier (theory knowledge)__setting,"ChartQA (relaxed accuracy, test)","ChartQA (relaxed accuracy, test)__setting",Codeforces Rating,Codeforces Rating__setting,DROP,DROP__setting,"Document Visual QA (ANLS, test)","Document Visual QA (ANLS, test)__setting",GPQA,GPQA__setting,GPQA (Diamond),GPQA (Diamond)__setting,GRE Quantitative,GRE Quantitative__setting,GRE Reading & Writing,GRE Reading & Writing__setting,GRE Verbal,GRE Verbal__setting,GRE Writing,GRE Writing__setting,GSM8K,GSM8K__setting,HellaSwag,HellaSwag__setting,HumanEval,HumanEval__setting,HumanEval+,HumanEval+__setting,Introductory Sommelier (theory knowledge),Introductory Sommelier (theory knowledge)__setting,LSAT,LSAT__setting,LeetCode (easy),LeetCode (easy)__setting,LeetCode (hard),LeetCode (hard)__setting,LeetCode (medium),LeetCode (medium)__setting,MATH,MATH__setting,MBPP,MBPP__setting,MBPP+,MBPP+__setting,MGSM,MGSM__setting,MMLU,MMLU__setting,MMLU-Pro,MMLU-Pro__setting,MMLU-redux,MMLU-redux__setting,MMLU-stem,MMLU-stem__setting,MMMU,MMMU__setting,MMMU (val),MMMU (val)__setting,MathVista (testmini),MathVista (testmini)__setting,Medical Knowledge Self-Assessment Program,Medical Knowledge Self-Assessment Program__setting,Multi-Exam,Multi-Exam__setting,Multi-Mathematics,Multi-Mathematics__setting,Multi-Translation,Multi-Translation__setting,Multi-Understanding,Multi-Understanding__setting,MultiChallenge (Scale),MultiChallenge (Scale)__setting,MultiPL-E,MultiPL-E__setting,Natural Questions,Natural Questions__setting,SAT Evidence-Based Reading & Writing,SAT Evidence-Based Reading & Writing__setting,SAT Math,SAT Math__setting,SWE-bench Verified,SWE-bench Verified__setting,StrategyQA,StrategyQA__setting,TheoremQA,TheoremQA__setting,TriviaQA,TriviaQA__setting,TruthfulQA,TruthfulQA__setting,USABO Semifinal Exam 2020,USABO Semifinal Exam 2020__setting,USNCO Local Section Exam 2022,USNCO Local Section Exam 2022__setting,Uniform Bar Exam (MBE+MEE+MPT),Uniform Bar Exam (MBE+MEE+MPT)__setting,"Video-MME (long, no subtitles)","Video-MME (long, no subtitles)__setting",WinoGrande,WinoGrande__setting,XCOPA,XCOPA__setting,Needle In A Haystack (1M tokens),Needle In A Haystack (1M tokens)__setting,C-Eval,C-Eval__setting,CMMLU,CMMLU__setting,IFEval,IFEval__setting,Codeforces,Codeforces__setting,IMO Qualifying Exam,IMO Qualifying Exam__setting,MathVista,MathVista__setting,AIME (unspecified),AIME (unspecified)__setting,AIME '24,AIME '24__setting,AIME 2025,AIME 2025__setting,MMMLU,MMMLU__setting,SWE-Lancer Diamond,SWE-Lancer Diamond__setting,Aider Polyglot,Aider Polyglot__setting,HealthBench Hard,HealthBench Hard__setting,SimpleQA,SimpleQA__setting,C-SimpleQA,C-SimpleQA__setting,Arena-Hard,Arena-Hard__setting,Terminal-bench,Terminal-bench__setting,OSWorld,OSWorld__setting,SuperGPQA,SuperGPQA__setting,EvalPlus,EvalPlus__setting,CRUX-O,CRUX-O__setting,INCLUDE,INCLUDE__setting,CRUX-I,CRUX-I__setting,CMATH,CMATH__setting,LiveCodeBench,LiveCodeBench__setting,BFCL v3,BFCL v3__setting,TAU-Bench,TAU-Bench__setting,MATH 500,MATH 500__setting,Tau2-Bench,Tau2-Bench__setting,ACEBench (En),ACEBench (En)__setting,SWE-Bench Multilingual,SWE-Bench Multilingual__setting,OJBench,OJBench__setting,Beyond AIME,Beyond AIME__setting,Codeforces avg@8,Codeforces avg@8__setting,Codeforces pass@8,Codeforces pass@8__setting,ARC-AGI,ARC-AGI__setting,Collie,Collie__setting,HLE,HLE__setting,HLE (w/ Tools),HLE (w/ Tools)__setting,HMMT Feb. 2025,HMMT Feb. 2025__setting,HMMT Nov. 2025,HMMT Nov. 2025__setting,IMOAnswerBench,IMOAnswerBench__setting,LiveCodeBench-v6,LiveCodeBench-v6__setting,Terminal Bench Hard,Terminal Bench Hard__setting,Terminal Bench 2.0,Terminal Bench 2.0__setting,BrowseComp,BrowseComp__setting,BrowseComp (w/ Context Manage),BrowseComp (w/ Context Manage)__setting,BrowseComp-ZH,BrowseComp-ZH__setting,LMArena Leaderboard,LMArena Leaderboard__setting,WebDev Arena,WebDev Arena__setting,MathArena Apex,MathArena Apex__setting,MMMU-Pro,MMMU-Pro__setting,Video-MMMU,Video-MMMU__setting,SimpleQA Verified,SimpleQA Verified__setting,SWE-bench Multilingual,SWE-bench Multilingual__setting
GPT-3.5 (ChatGPT),OpenAI,2022-11-30,https://openai.com/blog/chatgpt,reports/combined_report.md,No benchmark scores reported in the release post.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GPT-4,OpenAI,2023-03-14,https://ar5iv.labs.arxiv.org/html/2303.08774,reports/combined_report.md,,,,30/150 (6th-12th percentile) (reported score),Exam simulation (per GPT-4 technical report),60/150 (45th-66th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (86th-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (85th-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),4 (43rd-59th percentile) (reported score),Exam simulation (per GPT-4 technical report),4 (71st-88th percentile) (reported score),Exam simulation (per GPT-4 technical report),2 (14th-44th percentile) (reported score),Exam simulation (per GPT-4 technical report),2 (8th-22nd percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (91st-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (84th-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (82nd-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),4 (66th-84th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (83rd-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (85th-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (88th-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),5 (89th-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),4 (65th-87th percentile) (reported score),Exam simulation (per GPT-4 technical report),,,77% (reported score),Exam simulation (per GPT-4 technical report),,,,,,,86% (reported score),Exam simulation (per GPT-4 technical report),,,392 (below 5th percentile) (reported score),Exam simulation (per GPT-4 technical report),,,,,,,,,163/170 (~80th percentile) (reported score),Exam simulation (per GPT-4 technical report),,,169/170 (~99th percentile) (reported score),Exam simulation (per GPT-4 technical report),4/6 (~54th percentile) (reported score),Exam simulation (per GPT-4 technical report),,,,,,,,,92% (reported score),Exam simulation (per GPT-4 technical report),163 (~88th percentile) (reported score),Exam simulation (per GPT-4 technical report),31/41 (reported score),Exam simulation (per GPT-4 technical report),3/45 (reported score),Exam simulation (per GPT-4 technical report),21/80 (reported score),Exam simulation (per GPT-4 technical report),,,,,,,,,,,,,,,,,,,,,,,75% (reported score),Exam simulation (per GPT-4 technical report),,,,,,,,,,,,,,,710/800 (~93rd percentile) (reported score),Exam simulation (per GPT-4 technical report),700/800 (~89th percentile) (reported score),Exam simulation (per GPT-4 technical report),,,,,,,,,,,87/150 (99th-100th percentile) (reported score),Exam simulation (per GPT-4 technical report),36/60 (85th-95th percentile) (reported score),Exam simulation (per GPT-4 technical report),298/400 (~90th percentile) (reported score),Exam simulation (per GPT-4 technical report),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PaLM 2-L,Google,2023-05-10,https://ai.google/static/documents/palm2techreport.pdf,reports/combined_report.md,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,95.1 (accuracy),4-shot CoT+SC,,,78.1 (accuracy),3-shot CoT,,,90.4 (accuracy),7-shot,,,,,,,85.0 (F1),3-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,90.4 (accuracy),6-shot,,,,,,,,,,,,,,,90.9 (accuracy),5-shot,94.4 (accuracy),4-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude 2,Anthropic,2023-07-11,https://www.anthropic.com/news/claude-2,reports/combined_report.md,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,76.5% (accuracy),multiple-choice section,,,,,,,,,,,,,,,,,,,above 90th percentile (percentile),standardized exam,,,,,88.0% (accuracy),grade school math,,,71.2% (pass@1),code generation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GPT-4 Turbo,OpenAI,2023-11-06,https://openai.com/index/new-models-and-developer-products-announced-at-devday/,reports/combined_report.md,No benchmark scores reported in the release post.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude 2.1,Anthropic,2023-11-21,https://www.anthropic.com/news/claude-2-1,reports/combined_report.md,No benchmark scores reported in the release post.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gemini 1.0 Ultra,Google DeepMind,2023-12-06,https://blog.google/intl/en-africa/company-news/technology/introducing-gemini-our-largest-and-most-capable-ai-model/,reports/combined_report.md,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,90.0 (accuracy),Gemini MMLU (reasoning) per blog,,,,,,,59.4 (accuracy),MMMU benchmark,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GLM-4 (flagship),Zhipu AI,2024-01-17,https://www.glm-4.com/,reports/combined_report.md,Official benchmark scores not found in source; left blank.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gemini 1.5 Pro,Google,2024-02-15,https://blog.google/innovation-and-ai/products/google-gemini-next-generation-model-february-2024/,reports/combined_report.md,Release post focuses on long-context evaluations; limited benchmark scores reported.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,99,NIAH; 1M tokens; accuracy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mistral Large,Mistral AI,2024-02-26,https://mistral.ai/fr/news/mistral-large,reports/combined_report.md,Scores extracted from benchmark figures in release post.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,94.2,5-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,91.21,"maj@8, 8-shot",89.2,10-shot,45.1,pass@1 (not disclosed),,,,,,,,,,,,,45.0,maj@4,73.1,pass@1 (not disclosed),,,,,81.2,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.7,5-shot,50.5,not disclosed,,,,,,,,,86.7,5-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude 3 Opus,Anthropic,2024-03-04,https://www.anthropic.com/news/claude-3-family,reports/combined_report.md,,88.1% (accuracy),test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,96.4% (accuracy),25-shot,,,86.8% (accuracy),3-shot CoT,,,,,,,80.8% (accuracy),0-shot CoT,,,83.1 (F1),3-shot (F1),89.3% (ANLS),ANLS (test),,,50.4% (accuracy),0-shot CoT,,,,,,,,,95.0% (accuracy),0-shot CoT,95.4% (accuracy),10-shot,84.9% (pass@1),0-shot,,,,,,,,,,,,,60.1% (accuracy),0-shot CoT,,,,,90.7% (accuracy),0-shot,86.8% (accuracy),5-shot,,,,,,,,,59.4% (accuracy),MMMU (val),50.5% (accuracy),CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude 3 Sonnet,Anthropic,2024-03-04,https://www.anthropic.com/news/claude-3-family,reports/combined_report.md,,88.7% (accuracy),test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,93.2% (accuracy),25-shot,,,82.9% (accuracy),3-shot CoT,,,,,,,81.1% (accuracy),0-shot CoT,,,78.9 (F1),3-shot (F1),89.5% (ANLS),ANLS (test),,,40.4% (accuracy),0-shot CoT,,,,,,,,,92.3% (accuracy),0-shot CoT,89.0% (accuracy),10-shot,73.0% (pass@1),0-shot,,,,,,,,,,,,,43.1% (accuracy),0-shot CoT,,,,,83.5% (accuracy),0-shot,79.0% (accuracy),5-shot,,,,,,,,,53.1% (accuracy),MMMU (val),47.9% (accuracy),CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Grok-1,xAI,2024-03-28,https://x.ai/news/grok-1.5,reports/combined_report.md,Benchmarks for Grok-1 reported in Grok-1.5 announcement.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62.9 (accuracy),8-shot,,,63.2 (pass@1),0-shot,,,,,,,,,,,,,23.9 (accuracy),4-shot,,,,,,,73.0 (accuracy),5-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Grok-1.5,xAI,2024-03-28,https://x.ai/news/grok-1.5,reports/combined_report.md,Benchmarks from Grok-1.5 announcement table.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,90.0,8-shot,,,74.1,0-shot,,,,,,,,,,,,,50.6,4-shot,,,,,,,81.3,5-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Command R+,Cohere,2024-04-01,https://huggingface.co/CohereLabs/c4ai-command-r-plus/blob/main/README.md,reports/combined_report.md,Release date approximate; official model card does not state a date.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70.99 (accuracy),not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70.7 (accuracy),not disclosed,88.6 (accuracy),not disclosed,,,,,,,,,,,,,,,,,,,,,,,75.7 (accuracy),not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,56.3 (accuracy),not disclosed,,,,,,,,,85.4 (accuracy),not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeepSeek-V2,DeepSeek,2024-05-06,https://github.com/deepseek-ai/DeepSeek-V2,reports/combined_report.md,Base model benchmark table from repo; settings not specified.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.9,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,79.2,not disclosed,,,48.8,not disclosed,,,,,,,,,,,,,43.6,not disclosed,66.6,not disclosed,,,,,78.5,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.7,not disclosed,84.0,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GPT-4o,OpenAI,2024-05-13,https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/,reports/combined_report.md,No benchmark scores reported in the release post.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniMax (flagship),MiniMax,2024-06-01,,reports/combined_report.md,Official release/tech report source not located in this loop; benchmarks left blank.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude 3.5 Sonnet,Anthropic,2024-06-21,https://www.anthropic.com/news/claude-3-5-sonnet,reports/combined_report.md,Footnote result from release post.,94.7% (accuracy),0-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,93.1% (accuracy),3-shot CoT,,,,,,,90.8% (accuracy),0-shot CoT,,,87.1 (F1),3-shot,95.2% (ANLS),0-shot,,,59.4% (accuracy) | 67.2% (accuracy),"0-shot CoT | 5-shot CoT, maj@32",,,,,,,,,96.4% (accuracy),0-shot CoT,,,92.0% (pass@1),0-shot,,,,,,,,,,,,,71.1% (accuracy),0-shot CoT,,,,,91.6% (accuracy),0-shot CoT,88.7% (accuracy) | 88.3% (accuracy) | 90.4% (accuracy),5-shot | 0-shot CoT | 5-shot CoT,,,,,,,,,68.3% (accuracy),0-shot CoT,67.7% (accuracy),0-shot CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Llama 3.1 405B (Instruct),Meta,2024-07-23,https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct-FP8,reports/combined_report.md,Scores from Meta Llama 3.1 405B Instruct model card.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,96.9,0-shot,,,,,,,,,,,,,,,,,,,50.7,0-shot,,,,,,,,,,,96.8,8-shot CoT,,,89.0,0-shot,,,,,,,,,,,,,73.8,0-shot CoT,88.6,0-shot,,,,,88.6,0-shot CoT,73.3,5-shot CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,88.6,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mistral Large 2,Mistral AI,2024-07-24,https://mistral.ai/news/mistral-large-2407,reports/combined_report.md,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.0 (accuracy),pretrained,,,,,,,,,,,,,,,,,,,,,,,,,76.9 (accuracy),average (MultiPL-E),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Grok-2,xAI,2024-08-13,https://x.ai/news/grok-2/,reports/combined_report.md,Beta release; settings per xAI benchmark table.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,93.6,0-shot CoT,56.0,0-shot CoT,,,,,,,,,,,,,,,88.4,pass@1,,,,,,,,,,,,,76.1,maj@1,,,,,,,87.5,0-shot CoT,75.5,0-shot CoT,,,,,66.1,0-shot CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69.0,0-shot CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OpenAI o1 (preview),OpenAI,2024-09-12,https://openai.com/index/introducing-openai-o1-preview/,reports/combined_report.md,"Release post reports reasoning benchmarks (IMO qualifier, Codeforces percentile).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,89,percentile,83,percentage correct,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeepSeek-V3,DeepSeek,2024-12-26,https://github.com/deepseek-ai/DeepSeek-V3,reports/combined_report.md,Release date approximated; base model benchmark table from repo.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,95.3,25-shot,,,87.5,3-shot,,,,,,,,,,,89.0,3-shot F1,,,,,,,,,,,,,,,,,88.9,10-shot,,,,,,,,,,,,,,,,,,,,,,,87.1,5-shot,64.4,EM (5-shot),86.2,EM (5-shot),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.9,5-shot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeepSeek-R1,DeepSeek,2025-01-15,https://github.com/deepseek-ai/DeepSeek-R1,reports/combined_report.md,Release date approximated; benchmark table from repo.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,92.2,3-shot F1,,,,,71.5,Pass@1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,90.8,Pass@1,84.0,EM,92.9,EM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,83.3,Prompt Strict,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniMax-Text-01,MiniMax,2025-01-15,https://github.com/MiniMax-AI/MiniMax-01,reports/combined_report.md,Release announced 2025-01-15 on MiniMax news; benchmarks from MiniMax-01 tech report table (0-shot CoT).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,87.8,0-shot CoT; F1,,,,,54.4,0-shot CoT,,,,,,,,,94.8,0-shot CoT,,,86.9,0-shot CoT,,,,,,,,,,,,,77.4,0-shot CoT,,,71.7,0-shot CoT,,,88.5,0-shot CoT,75.7,0-shot CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,89.1,0-shot CoT,,,,,,,,,,,,,,,,,,,,,23.7,0-shot CoT,67.4,0-shot CoT,89.1,0-shot CoT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kimi k1.5,Moonshot AI,2025-01-22,https://huggingface.co/papers/2501.12599,reports/combined_report.md,Benchmarks from technical report abstract (via Hugging Face papers page).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,94,percentile,,,74.9,not disclosed,77.5,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47.3,short-CoT,,,,,96.2,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GPT-4.5,OpenAI,2025-02-27,https://openai.com/index/introducing-gpt-4-5/,reports/combined_report.md,Benchmarks from GPT-4.5 appendix; numbers shown are best internal performance.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71.4,best internal performance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74.4,best internal performance,,,,,,,,,,,,,,,,,,,,,,,,,38.0,best internal performance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,36.7,best internal performance,,,85.1,best internal performance,32.6,best internal performance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Seed-Thinking-v1.5,ByteDance (Seed),2025-04-10,https://github.com/ByteDance-Seed/Seed-Thinking-v1.5,reports/combined_report.md,Release date from Seed publications page; benchmarks from GitHub README table.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77.3,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,87.0,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47.0,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,87.4,not disclosed,,,,,,,,,86.7,not disclosed,74.0,not disclosed,,,,,54.2,not disclosed,,,12.9,not disclosed,,,,,,,,,62.1,not disclosed,,,,,,,,,,,64.9,v5,,,,,,,,,,,,,,,48.0,not disclosed,36.3,not disclosed,55.0,not disclosed,39.9,not disclosed,73.1,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GPT-4.1,OpenAI,2025-04-14,https://openai.com/index/gpt-4-1/,reports/combined_report.md,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,38.3,not disclosed,,,,,,,,,54.6,not disclosed,,,,,,,,,,,,,,,72.0,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OpenAI o3,OpenAI,2025-04-16,https://openai.com/index/introducing-o3-and-o4-mini/,reports/combined_report.md,"Release post cites SOTA on Codeforces, SWE-bench, and MMMU without numeric scores.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Qwen3-235B-A22B,Alibaba (Qwen),2025-05-14,https://ar5iv.labs.arxiv.org/html/2505.09388v1,reports/combined_report.md,"Flagship MoE (235B total, 22B active) from Qwen3 technical report.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,88.87,base pre-trained; setting not disclosed,,,,,,,,,,,,,,,47.47,base pre-trained; setting not disclosed,,,,,,,,,,,94.39,base pre-trained; setting not disclosed,,,,,,,,,,,,,,,,,71.84,base pre-trained; setting not disclosed,81.40,base pre-trained; setting not disclosed,,,83.53,base pre-trained; setting not disclosed,87.81,base pre-trained; setting not disclosed,68.18,base pre-trained; setting not disclosed,87.40,base pre-trained; setting not disclosed,,,,,,,,,,,,,,,,,,,,,65.94,base pre-trained; setting not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2056,ELO,,,,,,,85.7,base model,81.5,base model,86.70,base pre-trained; setting not disclosed,,,,,,,,,,,,,,,,,44.06,base pre-trained; setting not disclosed,77.60,base pre-trained; setting not disclosed,79.00,base pre-trained; setting not disclosed,73.46,base pre-trained; setting not disclosed,,,,,70.7,v5 (24.12-25.02),70.8,average,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude Opus 4,Anthropic,2025-05-22,https://www.anthropic.com/news/claude-4,reports/combined_report.md,Benchmarks from Claude 4 launch post appendix; no extended thinking unless noted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74.9,no extended thinking (appendix),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73.7,no extended thinking (appendix),,,,,,,,,,,,,,,,,,,,,,,,,72.5,no extended thinking; full 500 tasks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,33.9,no extended thinking (appendix),,,,,87.4,no extended thinking (appendix),,,,,,,,,,,,,43.2,no extended thinking,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude Sonnet 4,Anthropic,2025-05-22,https://www.anthropic.com/news/claude-4,reports/combined_report.md,Benchmarks from Claude 4 launch post appendix; no extended thinking unless noted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70.0,no extended thinking (appendix),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72.6,no extended thinking (appendix),,,,,,,,,,,,,,,,,,,,,,,,,72.7,no extended thinking; full 500 tasks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,33.1,no extended thinking (appendix),,,,,85.4,no extended thinking (appendix),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hunyuan-Large,Tencent,2025-06-27,https://huggingface.co/tencent/Hunyuan-A13B-Instruct/blob/c1ef5aa7f0c8fef68b3f859c89232013563a8030/README.md,reports/combined_report.md,Benchmarks from Hunyuan-A13B-Instruct README base model table.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.45,not disclosed,,,,,,,,,,,,,,,41.34,not disclosed,,,,,,,,,,,90.96,not disclosed,,,,,,,,,,,,,,,,,67.31,not disclosed,69.30,not disclosed,,,,,88.40,not disclosed,65.80,not disclosed,87.10,not disclosed,,,,,,,,,,,,,,,,,,,,,52.94,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,39.36,not disclosed,62.86,not disclosed,70.67,not disclosed,,,56.70,not disclosed,84.06,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kimi K2,Moonshot AI,2025-07-28,https://huggingface.co/papers/2507.20534,reports/combined_report.md,Benchmarks from technical report abstract (via Hugging Face papers page).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.1,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65.8,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,49.5,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,53.7,v6,,,,,97.4,not disclosed,66.1,not disclosed,76.5,not disclosed,47.3,not disclosed,27.1,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude Opus 4.1,Anthropic,2025-08-05,https://www.anthropic.com/news/claude-opus-4-1,reports/combined_report.md,Release post reports SWE-bench Verified.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74.5,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GPT-5,OpenAI,2025-08-07,https://openai.com/index/introducing-gpt-5/,reports/combined_report.md,Benchmarks from GPT-5 release post.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.2,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,74.9,n=477 verified tasks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,94.6,without tools,,,,,88.0,not disclosed,46.2,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GLM-4.5,Zhipu AI (Z.ai),2025-08-08,https://huggingface.co/zai-org/GLM-4.5-FP8/blob/main/README.md,reports/combined_report.md,Model card reports 355B total parameters; benchmarks from README abstract.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64.2,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,91.0,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70.1,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Claude Sonnet 4.5,Anthropic,2025-09-29,https://www.anthropic.com/news/claude-sonnet-4-5,reports/combined_report.md,Benchmarks from launch post; SWE-bench Verified average over 10 trials with 200K thinking budget.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77.2,200K thinking budget; avg over 10 trials,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,61.4,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gemini 3.0,Google,2025-11-18,https://blog.google/products-and-platforms/products/gemini/gemini-3/,reports/combined_report.md,Benchmarks from Gemini 3 launch post (Gemini 3 Pro numbers).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,91.9,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,76.2,not disclosed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,37.5,without tools,,,,,,,,,,,,,54.2,not disclosed,,,,,,,1501,Elo,1487,Elo,23.4,not disclosed,81.0,not disclosed,87.6,not disclosed,72.1,not disclosed,,
Claude Opus 4.5,Anthropic,2025-11-24,https://www.anthropic.com/news/claude-opus-4-5,reports/combined_report.md,Release post provides qualitative benchmark claims; numeric scores are in images/system card and not captured in this run.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GLM-4.7,Zhipu AI (Z.ai),2025-12-22,https://z.ai/blog/glm-4.7,reports/combined_report.md,Benchmarks from GLM-4.7 release post table.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.7,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.3,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73.8,"temperature 0.7, top-p 1.0, max new tokens 16384",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,95.7,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,87.4,"temperature 0, max new tokens 16384; preserved thinking",,,,,,,,,,,,,,,,,24.8,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",42.8,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",97.1,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",93.5,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",82.0,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",84.9,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",33.3,"temperature 0.7, top-p 1.0, max new tokens 16384",41.0,"temperature 0.7, top-p 1.0, max new tokens 16384",52.0,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",67.5,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",66.6,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,66.7,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)"
GLM-4.6,Zhipu AI (Z.ai),2025-12-22,https://z.ai/blog/glm-4.7,reports/combined_report.md,Benchmarks from GLM-4.7 release post table; GLM-4.6 release date not specified in source.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.0,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,83.2,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,68.0,"temperature 0.7, top-p 1.0, max new tokens 16384",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,93.9,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.2,"temperature 0, max new tokens 16384; preserved thinking",,,,,,,,,,,,,,,,,17.2,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",30.4,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",89.2,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",87.7,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",73.5,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",82.8,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",23.6,"temperature 0.7, top-p 1.0, max new tokens 16384",24.5,"temperature 0.7, top-p 1.0, max new tokens 16384",45.1,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",57.5,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",49.5,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)",,,,,,,,,,,,,53.8,"default settings (temp 1.0, top-p 0.95, max new tokens 131072)"
